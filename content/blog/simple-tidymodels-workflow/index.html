---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/
title: "A Basic XGBoost Tidymodels Workflow"
subtitle: ""
summary: "We will use the diamonds dataset to perform a simple tidymodels workflow to predict the price of the diamond by feeding several physical attributes to the algorithm."
authors: ["Luis Dominguez"]
tags: ["r","EDA","tidyverse"]
categories: ["r","EDA","tidyverse"]
date: 2021-04-30T00:22:27-06:00
lastmod: 2021-04-30T00:22:27-06:00
featured: true
draft: false
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: "The Glorious Studio"
  focal_point: "Smart"
  preview_only: true
projects: []
editor_options: 
  chunk_output_type: console
---

<script src="index_files/header-attrs/header-attrs.js"></script>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The goal of this post is to set the ground of a <a href="https://www.tidymodels.org/">tidymodels</a> workflow. We will define the model, the preprocessing recipe, tune the model paramenters, and evaluate our predictions.we will use the <a href="https://ggplot2.tidyverse.org/reference/diamonds.html">diamonds dataset</a> that comes with <a href="https://ggplot2.tidyverse.org/index.html">ggplot2</a>. We will predict diamonds price based on their cut, colour, clarity &amp; other attributes and it also covers the building a simple linear regression model using <a href="https://www.tidymodels.org/">tidymodels</a>.</p>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<pre class="r"><code>head(diamonds)</code></pre>
<pre><code>## # A tibble: 6 x 10
##   carat cut       color clarity depth table price     x     y     z
##   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 0.23  Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43
## 2 0.21  Premium   E     SI1      59.8    61   326  3.89  3.84  2.31
## 3 0.23  Good      E     VS1      56.9    65   327  4.05  4.07  2.31
## 4 0.290 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63
## 5 0.31  Good      J     SI2      63.3    58   335  4.34  4.35  2.75
## 6 0.24  Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48</code></pre>
<p>The goal of this post is not performing an eda of this dataset, so I will not spend too long exploring the data. I will include a quick glimpse for context.</p>
<pre class="r"><code>library(skimr)

skim(diamonds)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">diamonds</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">53940</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">10</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cut</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">5</td>
<td align="left">Ide: 21551, Pre: 13791, Ver: 12082, Goo: 4906</td>
</tr>
<tr class="even">
<td align="left">color</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">7</td>
<td align="left">G: 11292, E: 9797, F: 9542, H: 8304</td>
</tr>
<tr class="odd">
<td align="left">clarity</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">8</td>
<td align="left">SI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">carat</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.80</td>
<td align="right">0.47</td>
<td align="right">0.2</td>
<td align="right">0.40</td>
<td align="right">0.70</td>
<td align="right">1.04</td>
<td align="right">5.01</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="even">
<td align="left">depth</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">61.75</td>
<td align="right">1.43</td>
<td align="right">43.0</td>
<td align="right">61.00</td>
<td align="right">61.80</td>
<td align="right">62.50</td>
<td align="right">79.00</td>
<td align="left">▁▁▇▁▁</td>
</tr>
<tr class="odd">
<td align="left">table</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">57.46</td>
<td align="right">2.23</td>
<td align="right">43.0</td>
<td align="right">56.00</td>
<td align="right">57.00</td>
<td align="right">59.00</td>
<td align="right">95.00</td>
<td align="left">▁▇▁▁▁</td>
</tr>
<tr class="even">
<td align="left">price</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3932.80</td>
<td align="right">3989.44</td>
<td align="right">326.0</td>
<td align="right">950.00</td>
<td align="right">2401.00</td>
<td align="right">5324.25</td>
<td align="right">18823.00</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">x</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.73</td>
<td align="right">1.12</td>
<td align="right">0.0</td>
<td align="right">4.71</td>
<td align="right">5.70</td>
<td align="right">6.54</td>
<td align="right">10.74</td>
<td align="left">▁▁▇▃▁</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.73</td>
<td align="right">1.14</td>
<td align="right">0.0</td>
<td align="right">4.72</td>
<td align="right">5.71</td>
<td align="right">6.54</td>
<td align="right">58.90</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">z</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.54</td>
<td align="right">0.71</td>
<td align="right">0.0</td>
<td align="right">2.91</td>
<td align="right">3.53</td>
<td align="right">4.04</td>
<td align="right">31.80</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<p>Anyone who has seen any heist movies knows that carat and price are highly correlated. A carat is the unit of weight for precious stones and pearls, now equivalent to 200 milligrams.</p>
<p>We will also check for correlation with other features.</p>
<pre class="r"><code>diamonds %&gt;%
  select_if(is.numeric) %&gt;%
  cor() %&gt;%
  as_tibble(rownames = &quot;variable1&quot;) %&gt;%
  pivot_longer(
    cols = -variable1,
    names_to = &quot;variable2&quot;
  ) %&gt;%
  filter(variable1 != variable2) %&gt;%
  ggplot(aes(variable1, variable2, label = round(value, 2), fill = value)) +
  geom_raster() +
  geom_text() +
  scale_fill_gradient2()</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-4-1.png" width="1800" /></p>
<p>The data is mostly clean, but I believe it will need some basic preprocessing.</p>
</div>
<div id="model" class="section level2">
<h2>Model</h2>
<div id="dataset-splits-and-folds" class="section level3">
<h3>Dataset Splits and Folds</h3>
<pre class="r"><code>library(tidymodels)

set.seed(2345)
split &lt;- initial_split(data = diamonds, strata = price)
train &lt;- training(split)
test &lt;- testing(split)</code></pre>
<pre class="r"><code>set.seed(123)
k_fold &lt;- vfold_cv(data = train, v = 5, strata = price)</code></pre>
</div>
<div id="preprocessing" class="section level3">
<h3>Preprocessing</h3>
<p>We don’t need much transformation in the <code>diamonds</code> dataset but we do need to transform our nominal (factors) predictors into dummy variables.</p>
<pre class="r"><code>library(themis)

xgb_recipe &lt;- recipe(price ~ ., data = train) %&gt;%
  step_dummy(all_nominal())</code></pre>
</div>
<div id="set-model-parameters" class="section level3">
<h3>Set Model Parameters</h3>
<p>There are a fair amount of parameters in a boosted tree. You can look at the <a href="https://parsnip.tidymodels.org/reference/boost_tree.html">general boosted tree parameters</a> to learn more about what they do.For now, we will focus on how to optimize the value of these parameters using the function <code>tune()</code>.</p>
<pre class="r"><code>xgb_specs &lt;- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune(),
  learn_rate = tune()
) %&gt;%
  set_engine(&quot;xgboost&quot;) %&gt;%
  set_mode(&quot;regression&quot;)</code></pre>
<p>Now that the parameters are set to <code>tune()</code>. We need to construct a grid with parameter values that they algorithm will try and evaluate what combination is the best. I like to use <code>grid_max_entropy()</code> because it supposed to give a good coverage. You can learn more about the different grid construction methods in the <a href="https://dials.tidymodels.org/">dials</a> package documentation.</p>
<pre class="r"><code>xgb_grid &lt;- grid_max_entropy(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_prop(),
  finalize(mtry(), train),
  learn_rate(),
  size = 10
)</code></pre>
</div>
<div id="tuning-workflow" class="section level3">
<h3>Tuning Workflow</h3>
<p><a href="https://yardstick.tidymodels.org/articles/metric-types.html">Yardstick metrics</a></p>
<pre class="r"><code>xgb_wf &lt;- workflow() %&gt;%
  add_model(xgb_specs) %&gt;%
  add_recipe(xgb_recipe)</code></pre>
<p>The next step is using our grid and resamples to tune the parameters through cross validation. To save building time, I ran the tuning locally and saved the results.</p>
<pre class="r"><code># doParallel::registerDoParallel()
#
# set.seed(896)
# tuning &lt;- tune_grid(
#   xgb_wf,
#   resamples = k_fold,
#   grid = xgb_grid,
#   metrics = metric_set(rmse,mae,mape),
#   control = control_grid(verbose = TRUE)
#
# )
#
# save(tuning, file = &quot;~/Documents/GitHub/personal_website/content/blog/simple-tidymodels-workflow/tuning.Rdata&quot;)

load(&quot;~/Documents/GitHub/personal_website/content/blog/simple-tidymodels-workflow/tuning.Rdata&quot;)

tuning</code></pre>
<pre><code>## # Tuning results
## # 5-fold cross-validation using stratification 
## # A tibble: 5 x 4
##   splits               id    .metrics           .notes          
##   &lt;list&gt;               &lt;chr&gt; &lt;list&gt;             &lt;list&gt;          
## 1 &lt;split [32.4K/8.1K]&gt; Fold1 &lt;tibble [30 × 10]&gt; &lt;tibble [0 × 1]&gt;
## 2 &lt;split [32.4K/8.1K]&gt; Fold2 &lt;tibble [30 × 10]&gt; &lt;tibble [0 × 1]&gt;
## 3 &lt;split [32.4K/8.1K]&gt; Fold3 &lt;tibble [30 × 10]&gt; &lt;tibble [0 × 1]&gt;
## 4 &lt;split [32.4K/8.1K]&gt; Fold4 &lt;tibble [30 × 10]&gt; &lt;tibble [0 × 1]&gt;
## 5 &lt;split [32.4K/8.1K]&gt; Fold5 &lt;tibble [30 × 10]&gt; &lt;tibble [0 × 1]&gt;</code></pre>
<p>The <code>metric_set()</code> function sets the chosen metrics to use in the selection process. Something to notice is that in classification problems you may need to tell the function what event should be considered as the “success” in <code>metric_set(..., event_level = "second")</code>, for example.</p>
<pre class="r"><code>show_best(tuning, metric = &quot;mape&quot;)</code></pre>
<pre><code>## # A tibble: 5 x 12
##    mtry min_n tree_depth learn_rate loss_reduction sample_size .metric
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
## 1     3    37          4  0.00828      0.000000445       0.469 mape   
## 2     8     6          8  0.000674     0.0585            0.571 mape   
## 3     3    13          3  0.000569    10.6               0.461 mape   
## 4     2    34          9  0.000541     0.0000954         0.100 mape   
## 5     2    20         15  0.0000125   11.4               0.256 mape   
## # … with 5 more variables: .estimator &lt;chr&gt;, mean &lt;dbl&gt;, n &lt;int&gt;,
## #   std_err &lt;dbl&gt;, .config &lt;chr&gt;</code></pre>
<pre class="r"><code>best_params &lt;- select_best(tuning, metric = &quot;mape&quot;)</code></pre>
</div>
</div>
<div id="evaluation" class="section level2">
<h2>Evaluation</h2>
<pre class="r"><code>xgb_final_wf &lt;- xgb_wf %&gt;%
  finalize_workflow(best_params)</code></pre>
<pre class="r"><code>xgb_final_fit &lt;- last_fit(xgb_final_wf,
  split = split,
  metrics = metric_set(rmse, mae, mape)
)

collect_metrics(xgb_final_fit)</code></pre>
<pre><code>## # A tibble: 3 x 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard       867.  Preprocessor1_Model1
## 2 mae     standard       472.  Preprocessor1_Model1
## 3 mape    standard        15.8 Preprocessor1_Model1</code></pre>
<p>It seems we didn’t overfit our model.</p>
<pre class="r"><code>pred &lt;- collect_predictions(xgb_final_fit)

pred %&gt;%
  ggplot(aes(price, .pred)) +
  geom_point(size = 0.3, color = &quot;midnightblue&quot;, alpha = 0.6) +
  geom_abline(slope = 1) +
  coord_fixed() +
  labs(x = &quot;Price&quot;, y = &quot;Prediction&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" width="1800" /></p>
<p>Our model does worse with expensive diamonds. It would be worth it to remove outliers before training. Let’s look at clarity and how the model perform in the different clarity categories.</p>
<pre class="r"><code>pred %&gt;%
  bind_cols(test %&gt;% select(-price)) %&gt;%
  mutate(perror = abs(.pred - price) / price) %&gt;%
  ggplot(aes(clarity, perror, fill = clarity)) +
  geom_boxplot(alpha = 0.3) +
  scale_y_sqrt() +
  labs(x = &quot;Clarity&quot;, y = &quot;Percent Error&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" width="1800" /></p>
<p>Our model struggles with I1 clarity but besides this, I think this was a good attempt on applying the <a href="https://www.tidymodels.org/">tidymodels</a> approach.</p>
<p><a href="https://www.pexels.com/@the-glorious-studio-3584518?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Photo credit</a></p>
</div>
